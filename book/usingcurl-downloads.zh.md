
## 下载

"下载"意味着从网络上的服务器获取数据,然后服务器显然被认为是"之上"的你.这是将数据从服务器加载到运行cURL的机器上.

下载可能是使用URL检索指向您机器上的特定数据的cURL最常用的情况.

### 下载到底是什么?

通过指定URL来指定要下载的资源.CURL默认下载URL,除非另有说明,URL标识下载的内容.在这个例子中,下载的URL是"[HTTP://Excel](http://example.com"):

```
curl http://example.com
```

URL被分解成单个的组件([正如在别处所解释的](cmdline-urls.md)正确的服务器被联系,然后被要求传送特定的资源,通常是一个文件.然后服务器传送数据,或者拒绝或可能是客户端请求错误数据,然后传递数据.

对资源的请求是特定于协议的,因此FTP://URL与HTTP//URL或SFFT://URL不同.

没有路径部分的URL,即只有主机名称部分的URL(如[HTTP://Excel](http://example.com)"上面的示例"将在内部添加一个斜杠('/'),然后这就是资源cURL将从服务器请求.

如果在命令行上指定多个URL,CURL将逐个下载每个URL.在第一个完成之前,它不会启动第二个传输,等等.

### 存储下载

如果您像上一节一样尝试下载示例,您将注意到除非被告知执行其他操作,否则curl会将下载的数据输出到stdout.将数据输出到stdout在您希望将其导入其他程序或类似程序时非常有用,但是它并不总是处理下载的最佳方式.

给CURL一个特定的文件名来保存下载`-o [filename]`用`--output`作为选项的长版本),其中文件名或者只是文件名、文件名的相对路径或者文件的完整路径.

还要注意的是,你可以把`-o`在URL之前或之后,没有区别:

```
curl -o output.html http://example.com/
curl -o /tmp/index.html http://example.com/
curl http://example.com -o ../../folder/savethis.html
```

当然,这并不限于HTTP\://URL,但不管您下载哪种类型的URL,都可以使用相同的方式:

```
curl -o file.txt ftp://example.com/path/to/file-name.ext
```

如果您要求curl将输出发送到终端,它试图检测和防止二进制数据被发送到那里,因为这可能严重扰乱您的终端(有时甚至到它基本停止工作的程度).您可以重写CURL的二进制输出防止,并强制输出通过使用发送到STDUT.`-o -`.

CURL有几种其他方法来存储和命名下载的数据.详情如下!

### 下载到由URL命名的文件

然而,许多URL已经包含最右边的文件名部分.CURL让你把它当作一个快捷方式,这样你就不用重复它了.`-o`. 因此,而不是:

```
curl -o file.html http://example.com/file.html
```

您可以将删除的URL资源保存到本地文件"文件.html"中:

```
curl -O http://example.com/file.html
```

这就是`-O`(大写字母O)选项,或`--remote-name`对于长名称版本.-o选项通过选择您提供的URL的文件名部分来选择要使用的本地文件名.这很重要.您指定URL,CURL从该数据中选择名称.如果站点进一步重定向curl(如果告诉curl跟随重定向),它不会更改curl用于存储该文件的文件名.

### 从服务器获取目标文件名

HTTP服务器可以提供一个名为`Content-Disposition:`作为回应.That header may contain a suggested file name for the contents delivered, and curl can be told to use that hint to name its local file. 这个`-J / --remote-header-name`启用此功能.如果您还使用`-O`选项,它使CURL默认使用URL中的文件名,并且仅使用*如果*实际上有一个有效的内容处置头可用,它切换到使用该名称保存.

\-J有一些问题和风险,用户需要意识到:

1.  It will only use the rightmost part of the suggested file name, so any path or directories the server suggests will be stripped out.

2.  Since the file name is entirely selected by the server, curl will, of course, overwrite any preexisting local file in your current directory if the server happens to provide such a file name.

3.  文件名编码和字符集问题.curl does not decode the name in any way, so you may end up with a URL-encoded file name where a browser would otherwise decode it to something more readable using a sensible character set.

### HTML与字符集

CURL将下载服务器发送的精确二进制数据.这对于您来说可能是很重要的,例如,您下载了HTML页面或其他文本数据,这些文本数据使用特定字符编码,然后您的浏览器将如预期那样显示这些字符编码.cURL然后不会翻译到达的数据.

一个常见的例子是,当用户下载网页时,会产生一些令人惊讶的结果:

```
curl https://example.com/ -o storage.html
```

……当检查时`storage.html`文件之后,用户意识到一个或多个字符看起来可笑或彻头彻尾的错误.这很可能是因为服务器使用字符集X发送字符,而编辑器和环境使用字符集Y.在理想的情况下,我们都会到处使用UTF-8,但不幸的是,情况仍然不是这样.

围绕这个问题的一个共同的工作是使用公共的.`iconv`实用工具将文本文件翻译成不同字符集.

### 压缩

curl允许您要求HTTP和HTTPS服务器提供数据的压缩版本,然后在到达时对其进行自动解压缩.在带宽比CPU更有限的情况下,这将帮助您在更短的时间内接收更多的数据.

HTTP压缩可以使用两种不同的机制来完成,一种被认为是"正确的方法",另一种是每个人实际使用的方法,并且是广泛流行的方法!压缩HTTP内容的常用方法是使用**内容编码**标题.你请求CURL使用这个`--compressed`选项:

```
curl --compressed http://example.com/
```

启用此选项后(如果服务器支持它),它将以压缩方式传递数据,curl将在保存数据或将其发送到stdout之前对其进行解压缩.这通常意味着,作为用户,除了可能注意到更快的传输之外,您实际上看不到或体验不到压缩.

这个`--compressed`选项要求使用支持的压缩算法之一进行内容编码压缩.还有稀罕的东西**传递编码**方法,它是为自动方法创建的,但从未真正被广泛采用.您可以告诉CURL请求传输编码压缩.`--tr-encoding`:

```
curl --tr-encoding http://example.com/
```

理论上,没有任何东西可以阻止您在同一命令行中使用这两者,但是在实践中,您可能会遇到,当要求以两种不同方式进行压缩时,一些服务器会感到有点混乱.只挑一个通常比较安全.

### 外壳重定向

当从shell或其他命令行提示系统调用curl时,该环境通常为您提供一组输出重定向功能.在大多数Linux和UNIX外壳和Windows的命令提示符下,将STDUT直接链接到一个文件`> filename`. 使用这个,当然,使用-O或-O多余的.

```
curl http://example.com/ > example.html
```

将输出重定向到文件会将所有输出从curl重定向到该文件,因此,即使您要求将多个URL传输到stdout,重定向输出将获得存储在单个文件中的所有URL输出.

```
curl http://example.com/1 http://example.com/2 > files
```

UNIX外壳通常允许您重定向*标准错误*单独流.stderr流通常是在终端中显示的流,但是您可以将它与stdout流分开重定向.STDUT流用于数据,而STDRR是元数据和错误等,而不是数据.您可以重定向STDRR.`2>file`这样地:

```
curl http://example.com > files.html 2>errors
```

### 多重下载

因为curl可以在单个命令行中下载许多URL,所以当然有时您希望将这些下载存储在名称良好的本地文件中.

理解这一点的关键是每个下载URL都需要自己的"存储指令".如果没有"存储指令",CURL将默认将数据发送到STDUT.如果你要求两个URL,只告诉CURL保存第一个URL,第二个URL被发送到STDUT.这样地:

```
curl -o one.html http://example.com/1 http://example.com/2
```

"存储指令"的读取和处理顺序与下载URL的顺序相同,因此它们不必以任何方式与URL相邻.您可以先将所有输出选项汇总,最后或与URL交错.你选择!

这些例子都是一样的:

```
curl -o 1.txt -o 2.txt http://example.com/1 http://example.com/2
curl http://example.com/1 http://example.com/2 -o 1.txt -o 2.txt
curl -o 1.txt http://example.com/1 http://example.com/2 -o 2.txt
curl -o 1.txt http://example.com/1 -o 2.txt http://example.com/2
```

这个`-O`类似的只是一个下载的指令,所以如果你下载多个URL,使用更多的URL:

```
curl -O -O http://example.com/1 http://example.com/2
```

### 为所有URL使用URL的文件名部分

作为添加一百的反应`-O`选项当使用一百个URL时,我们引入了一个选项`--remote-name-all`. 这使得`-O`所有给定URL的默认操作.你还可以为URL,但如果你离开了一个URL,下载提供个人存储指令",默认动作然后切换到O的风格.

### "我的浏览器显示了其他的东西"

一个很常见的情况是使用curl得到一个网址,你可以在你的浏览器,当你粘贴网址在浏览器的地址栏.

但浏览器获取URL做这么多,在这么多不同的方式比旋度,旋度显示在你的终端输出可能不是在所有你所看到的在你的浏览器窗口.

#### 客户差异

cURL只能得到你所要求的,它从不解析服务器提供的数据的实际内容.浏览器获取数据并激活不同的解析器,这取决于它认为内容是什么样的.例如,如果数据是HTML会解析它显示网页或者下载其他子资源如图像、JavaScript和CSS文件.当曲下载HTML将只得到单一的HTML资源,即使它的浏览器解析时,将引发全车更多的下载.如果你想卷下载任何子资源,你需要通过这些网址的cURL和要求才能得到这些,就像任何其他网址.

客户在他们怎样把他们的要求也不同,与资源请求的一些方面包括,例如,格式的喜好,要求压缩数据,或只是告诉服务器从上一页我们是"来自".CURL的请求与您的浏览器发送请求的方式略有不同.

#### 服务器差异

接收请求和提供的数据往往是安装程序的行为取决于什么样的客户认为与它的某些方面的服务器.有时是因为要为客户提供最好的内容是无辜的,有时是隐藏的一些内容,一些客户甚至尝试在特定浏览器的已知问题.还有,当然,各种登录系统,可能依赖于HTTP认证或饼干或客户端从预验证的IP地址范围.

有时候,使用CURL从服务器获得相同的响应作为浏览器的响应最终会非常困难.用户通常会记录他们的浏览器会话与浏览器的网络工具,然后进行比较,从cURL的记录的数据记录`--trace-ascii`选项并继续修改cURL的请求(通常与`-H / --header`)直到服务器开始对两者作出相同的响应.

这类工作既费时又乏味.您应该总是在服务器所有者或管理员允许的情况下这样做.

#### 中介机构的小提琴

中介机构是代理,显性的或隐性的.一些环境会迫使你使用一个或者你可以选择使用一个不同的原因,但也有透明的,拦截你的网络流量默默和代理为你不管你想要的是什么.

代理是"中间人",终止流量,然后代之以远程服务器.这可以引入各种显式滤波和"节约"你从某个内容甚至"保护"从什么数据你要发送到远程服务器,更介绍了协议如何工作和什么是正确的事情要做另一个软件的看法.

干扰中介机构经常引起很多头痛和神秘到彻头彻尾的内容恶意修改.

我们强烈建议您使用HTTPS或其他手段来验证您下载或上传的内容是真的,远程服务器发送给你,你珍贵的字节结束逐字在目的地的数据.

### 速率限制

当CURL传输数据时,它将尽可能快地进行.上传和下载都需要.如何快速将取决于几个因素,包括你的计算机的能力,自己的网络连接的带宽,在远程服务器上你转移到/从和延迟,服务器的负载.和你的卷发转移也可能与其他传输网络上的数据通过竞争,与其他用户或其他应用程序的用户.

然而在许多设置,你会发现你可以或多或少满足你自己的网络连接与一个单一的curl命令行.如果你有一个10兆位每秒的连接到互联网,那么cURL,可以使用所有这些10兆位数据传输.

对于大多数用例来说,尽可能多地使用带宽是一件好事.它使传输速度更快,这让curl命令完成早会使传输资源使用从服务器时间较短.

然而,有时你会发现,在本地网络连接上,用cURL扼杀掉其他网络功能是不方便的.在这些情况下,您可能希望告诉CURL减速,以便其他网络用户获得更好的机会获得他们的数据.用`--limit-rate
[speed]`您可以告诉CURL不超过每秒给定字节数的速度.速率限制值可以用字母k、m和g的字母后缀表示,千字节、兆字节和千兆字节.

使cURL不下载数据的速度快于每秒200千字节:

```
curl https://example.com/ --limit-rate 200K
```

给定的极限是最大值.*平均速度*允许,在整个转移过程中计数.这意味着CURL可以在短脉冲串中使用更高的传输速度,但是随着时间的推移,它使用的速率不超过给定的速率.

还请注意,cURL永远不知道最大可能的速度是什么,它将尽可能快地,并允许它.您可能知道您的连接的最大速度,但cURL不知道.

### 最大文件化

当你想确保你的cURL命令行不会尝试下载一个太大的文件,你可以命令CURL停止之前,如果它知道在传输开始之前的大小!也许这会占用太多的带宽,占用太长的时间,或者硬盘上没有足够的空间:

```
curl --max-filesize 100000 https://example.com/
```

给CURL最大的下载,你将接受的字节数,如果cURL可以计算出的大小在传输开始之前,它会中止之前尝试下载更大的东西.

在许多情况下,curl无法计算出传输开始时的大小,并且这个选项不会影响那些传输,即使它们最终可能大于指定的数量.

### 金属链

Malalink是一种文件描述标准,它告诉客户端多个位置相同的内容驻留在一起.然后客户端可以选择从这些源中的一个或多个传输内容.

CURL支持Malalink格式时,要求与`--metalink`选择权.然后,给定的URL应该指向一个Malalink文件.例如:

```
curl --metalink https://example.com/example.metalink
```

如果出现错误(例如文件或服务器不可用),curl将使用文件中列出的镜像进行故障转移.它也将验证文件在下载完成后的哈希.Malalink文件本身在内存中被下载和处理,而不存储在本地文件系统中.

### 在文件系统中存储元数据

当用CURL将下载保存到文件时,`--xattr`选项告诉CURL还将某些文件元数据存储在"扩展文件属性"中.假设使用支持的文件系统和操作系统之一,则这些扩展属性基本上是存储在文件系统中的标准化名称/值对.

当前,URL存储在`xdg.origin.url`属性,并且对于HTTP,内容类型存储在`mime_type`属性.如果文件系统在设置该选项时不支持扩展属性,则发出警告.

### 生的

什么时候?`--raw`使用,它禁用内容或传输编码的所有内部HTTP解码,而是使curl传递给未更改的原始数据.

如果您正在编写某种中间软件,并且希望将内容传递给另一个HTTP客户机,并允许它进行解码,则通常使用这种方法.

### 重试失败尝试

正常情况下,cURL只会尝试执行一次传输,如果不成功,则返回错误.使用`--retry`选项可以告诉CURL重试某些失败的传输.

如果CURL尝试执行传输时返回了一个瞬时错误,那么它将在放弃之前重试这个次数.将数字设置为0使得CURL不重试(默认为重试).瞬时错误意味着:超时、FTP 4xx响应代码或HTTP 5xx响应代码.

当curl将要重试传输时,它将首先等待一秒钟,然后对于所有即将到来的重试,它将使等待时间加倍,直到到达10分钟,然后这将是其余重试之间的延迟.使用`--retry-delay`您可以禁用此指数退避算法,并在尝试之间设置自己的延迟.用`--retry-max-time`你限制重试所允许的总时间.这个`--max-time`选项仍然会指定最长的时间,这些转让单是允许花费.

### 恢复和射程

恢复下载意味着首先检查本地已经存在的内容的大小,然后要求服务器发送其余内容,以便可以附加.cURL还允许恢复在自定义点的传输,而实际上没有任何已经在本地出现的东西.

CURL支持恢复在多个协议上的下载.告诉它在哪里开始转移`-C, --continue-at`选项,它使用一个简单的数值字节计数器偏移在哪里开始或字符串.`-`这就要求科尔根据自己知道的东西来理解它.使用时`-`curl将使用目标文件名来计算本地已经存在的数据量,并在向服务器请求更多数据时要求将其用作偏移量.

开始从字节偏移100下载FTP文件:

```
curl --continue-at 100 ftp://example.com/bigfile
```

继续下载以前中断的下载:

```
curl --continue-at - http://example.com/bigfile -O
```

如果您只想从远程资源传输的特定字节范围,您可以只要求.例如,当您只需要从偏移100中得到1000个字节时,就避免了下载整个巨大的远程文件:

```
curl --range 100-1999 http://example.com/bigfile
```
